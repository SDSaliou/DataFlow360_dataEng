services:
# ==================== 1. INGESTION (Python + Faker + APIs) ====================
  python_ingestion:
    build: ./collecte
    container_name: ingestion
    depends_on:
      cassandra:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./collecte:/app/collecte
      - ./ingestion:/app/ingestion
      - ./credentials:/app/credentials:ro
      - ./.env:/app/.env
    working_dir: /app
    environment:
      - PYTHONPATH=/app/collecte
      - CASSANDRA_HOST=cassandra
      - KAFKA_BOOTSTRAP=kafka:9092
      - AVIATIONSTACK_KEY=${AVIATIONSTACK_KEY} 
      - OPENWEATHER_KEY=${OPENWEATHER_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials/gcp-key.json
      - GCP_PROJECT_ID=dataflow-360
    command: >
      bash -c "
        # Si la clé GitHub Actions existe → on l'écrit, sinon on garde le fichier local
        if [ -n \"$${GCP_SA_KEY}\" ]; then
          echo \"\$${GCP_SA_KEY}\" > /app/credentials/gcp-key.json
          echo 'Clé GCP injectée via GitHub Secret'
        fi &&
        echo 'Lancement des producteurs API...' &&
        python /app/collecte/donnee_api/apiVols_producer.py > /app/logs_vols.log 2>&1 & 
        python /app/collecte/donnee_api/apiMeteo_producer.py > /app/logs_meteo.log 2>&1 & 
        echo 'Attente 30s...' &&
        sleep 30 &&
        echo 'Lancement du bridge vers Pub/Sub...' &&
        python /app/ingestion/pubsub_producer.py
      "
    ports:
      - "8000:8000"
    networks: [dataflow_net]
    restart: unless-stopped

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports: ["2181:2181"]
    networks: [dataflow_net]
    restart: unless-stopped

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:  
      zookeeper:
        condition: service_started
    ports: ["9092:9092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 10
    networks: [dataflow_net]
    restart: unless-stopped

  # Cassandra
  cassandra:
    image: cassandra:5.0
    container_name: cassandra
    ports: ["9042:9042"]
    environment:
      - CASSANDRA_CLUSTER_NAME=DataFlow360_Cluster
      - HEAP_NEWSIZE=512M
      - MAX_HEAP_SIZE=1024M
      - CASSANDRA_DC=DC1
      - CASSANDRA_RACK=RACK1
      - CASSANDRA_AUTHENTICATOR=AllowAllAuthenticator  
      - CASSANDRA_AUTHORIZER=AllowAllAuthorizer
    volumes:
      - cassandra_data:/var/lib/cassandra
    healthcheck:
      test: ["CMD", "cqlsh", "-e", "describe keyspaces"]
      interval: 10s
      timeout: 5s
      retries: 50
      start_period: 120s
    networks: [dataflow_net]
    restart: unless-stopped

volumes:
  cassandra_data:

networks:
  dataflow_net:
    driver: bridge